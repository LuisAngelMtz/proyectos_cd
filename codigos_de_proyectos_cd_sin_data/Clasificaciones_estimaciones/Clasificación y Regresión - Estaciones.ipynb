{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distributed-education",
   "metadata": {},
   "source": [
    "####### Se cuenta con estaciones de metro de todo México a través del tiempo y nos solicitan resolver dos problemáticas:\n",
    "\n",
    "- 1) Pronosticar la afluencia en cualquier estación\n",
    "- 2) Identificar si la estación estará en alta demanda ( si tiene un incremento de afluencia de 4 veces o más consecutivas )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-terminology",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ready-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ks_2samp\n",
    "from varclushi import VarClusHi\n",
    "from sklearn.feature_selection import VarianceThreshold \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scikitplot.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-minnesota",
   "metadata": {},
   "source": [
    "# Extracción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seventh-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = '/home/luis/Documentos/entornos/Ciencia de datos_git/Clasificaciones_estimaciones'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "representative-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_archi = os.listdir(ruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promising-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_archi = [os.path.join( ruta , f ) for f in lst_archi  if f[-3:] == 'csv'  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rocky-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(lst_archi[0], sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "advance-current",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afluencia</th>\n",
       "      <th>id_estacion</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61129</th>\n",
       "      <td>133075</td>\n",
       "      <td>Est00160</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239705</th>\n",
       "      <td>231348</td>\n",
       "      <td>Est00074</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149431</th>\n",
       "      <td>48811</td>\n",
       "      <td>Est00002</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34891</th>\n",
       "      <td>29973</td>\n",
       "      <td>Est00244</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197891</th>\n",
       "      <td>78773</td>\n",
       "      <td>Est00360</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95062</th>\n",
       "      <td>6104</td>\n",
       "      <td>Est00009</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122474</th>\n",
       "      <td>88076</td>\n",
       "      <td>Est00349</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42429</th>\n",
       "      <td>113585</td>\n",
       "      <td>Est00131</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184199</th>\n",
       "      <td>405</td>\n",
       "      <td>Est00218</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53611</th>\n",
       "      <td>148301</td>\n",
       "      <td>Est00213</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        afluencia id_estacion    t\n",
       "61129      133075    Est00160   57\n",
       "239705     231348    Est00074  291\n",
       "149431      48811    Est00002  431\n",
       "34891       29973    Est00244  163\n",
       "197891      78773    Est00360  454\n",
       "95062        6104    Est00009  457\n",
       "122474      88076    Est00349  669\n",
       "42429      113585    Est00131  352\n",
       "184199        405    Est00218  320\n",
       "53611      148301    Est00213  553"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-leonard",
   "metadata": {},
   "source": [
    "# Limpieza / Pretratamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "still-shark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "afluencia       int64\n",
       "id_estacion    object\n",
       "t               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "entire-voluntary",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Est00127    700\n",
       "Est00116    700\n",
       "Est00037    700\n",
       "Est00197    700\n",
       "Est00195    700\n",
       "           ... \n",
       "Est00256    699\n",
       "Est00356    699\n",
       "Est00094    699\n",
       "Est00034    699\n",
       "Est00320    699\n",
       "Name: id_estacion, Length: 390, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.id_estacion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opposite-trainer",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Est00127    0.256526\n",
       "Est00116    0.256526\n",
       "Est00037    0.256526\n",
       "Est00197    0.256526\n",
       "Est00195    0.256526\n",
       "              ...   \n",
       "Est00256    0.256159\n",
       "Est00356    0.256159\n",
       "Est00094    0.256159\n",
       "Est00034    0.256159\n",
       "Est00320    0.256159\n",
       "Name: id_estacion, Length: 390, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.id_estacion.value_counts(True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "scenic-brown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afluencia</th>\n",
       "      <th>id_estacion</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137957</td>\n",
       "      <td>Est00127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>343181</td>\n",
       "      <td>Est00127</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>454925</td>\n",
       "      <td>Est00127</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>393558</td>\n",
       "      <td>Est00127</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>336768</td>\n",
       "      <td>Est00127</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272872</th>\n",
       "      <td>405</td>\n",
       "      <td>Est00320</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272873</th>\n",
       "      <td>405</td>\n",
       "      <td>Est00320</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272874</th>\n",
       "      <td>405</td>\n",
       "      <td>Est00320</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272875</th>\n",
       "      <td>405</td>\n",
       "      <td>Est00320</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272876</th>\n",
       "      <td>405</td>\n",
       "      <td>Est00320</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272877 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        afluencia id_estacion    t\n",
       "0          137957    Est00127    1\n",
       "1          343181    Est00127    2\n",
       "2          454925    Est00127    5\n",
       "3          393558    Est00127    7\n",
       "4          336768    Est00127   13\n",
       "...           ...         ...  ...\n",
       "272872        405    Est00320  680\n",
       "272873        405    Est00320  693\n",
       "272874        405    Est00320  694\n",
       "272875        405    Est00320  695\n",
       "272876        405    Est00320  699\n",
       "\n",
       "[272877 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-outline",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "chief-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "um = ['id_estacion']\n",
    "t_min , t_max = df.t.min() , df.t.max()\n",
    "cols = range(t_min , t_max+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "second-madrid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 700)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_min, t_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "systematic-river",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272877, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alpha-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_piv = df.pivot_table( index=um , columns='t', values = 'afluencia' ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "automotive-pioneer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>t</th>\n",
       "      <th>id_estacion</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>691</th>\n",
       "      <th>692</th>\n",
       "      <th>693</th>\n",
       "      <th>694</th>\n",
       "      <th>695</th>\n",
       "      <th>696</th>\n",
       "      <th>697</th>\n",
       "      <th>698</th>\n",
       "      <th>699</th>\n",
       "      <th>700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Est00000</td>\n",
       "      <td>39059.0</td>\n",
       "      <td>74700.0</td>\n",
       "      <td>44356.0</td>\n",
       "      <td>237597.0</td>\n",
       "      <td>235918.0</td>\n",
       "      <td>181140.0</td>\n",
       "      <td>257563.0</td>\n",
       "      <td>257761.0</td>\n",
       "      <td>142208.0</td>\n",
       "      <td>...</td>\n",
       "      <td>370097.0</td>\n",
       "      <td>305425.0</td>\n",
       "      <td>311695.0</td>\n",
       "      <td>325139.0</td>\n",
       "      <td>240916.0</td>\n",
       "      <td>110586.0</td>\n",
       "      <td>394055.0</td>\n",
       "      <td>343256.0</td>\n",
       "      <td>374973.0</td>\n",
       "      <td>359923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Est00001</td>\n",
       "      <td>48321.0</td>\n",
       "      <td>368193.0</td>\n",
       "      <td>293510.0</td>\n",
       "      <td>295068.0</td>\n",
       "      <td>200780.0</td>\n",
       "      <td>236938.0</td>\n",
       "      <td>152211.0</td>\n",
       "      <td>283677.0</td>\n",
       "      <td>114380.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97849.0</td>\n",
       "      <td>51293.0</td>\n",
       "      <td>93265.0</td>\n",
       "      <td>116890.0</td>\n",
       "      <td>116176.0</td>\n",
       "      <td>109783.0</td>\n",
       "      <td>123092.0</td>\n",
       "      <td>79045.0</td>\n",
       "      <td>66206.0</td>\n",
       "      <td>94625.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Est00002</td>\n",
       "      <td>17515.0</td>\n",
       "      <td>49586.0</td>\n",
       "      <td>49395.0</td>\n",
       "      <td>42017.0</td>\n",
       "      <td>27076.0</td>\n",
       "      <td>38617.0</td>\n",
       "      <td>33000.0</td>\n",
       "      <td>43166.0</td>\n",
       "      <td>20616.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18127.0</td>\n",
       "      <td>12728.0</td>\n",
       "      <td>18583.0</td>\n",
       "      <td>21357.0</td>\n",
       "      <td>21351.0</td>\n",
       "      <td>20371.0</td>\n",
       "      <td>22105.0</td>\n",
       "      <td>19344.0</td>\n",
       "      <td>12476.0</td>\n",
       "      <td>17916.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Est00003</td>\n",
       "      <td>40677.0</td>\n",
       "      <td>240827.0</td>\n",
       "      <td>223303.0</td>\n",
       "      <td>190028.0</td>\n",
       "      <td>148294.0</td>\n",
       "      <td>148437.0</td>\n",
       "      <td>220882.0</td>\n",
       "      <td>253680.0</td>\n",
       "      <td>76196.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68953.0</td>\n",
       "      <td>55081.0</td>\n",
       "      <td>102738.0</td>\n",
       "      <td>92429.0</td>\n",
       "      <td>102303.0</td>\n",
       "      <td>101997.0</td>\n",
       "      <td>94795.0</td>\n",
       "      <td>90334.0</td>\n",
       "      <td>26519.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Est00004</td>\n",
       "      <td>82758.0</td>\n",
       "      <td>163112.0</td>\n",
       "      <td>144023.0</td>\n",
       "      <td>240623.0</td>\n",
       "      <td>243391.0</td>\n",
       "      <td>205486.0</td>\n",
       "      <td>220086.0</td>\n",
       "      <td>255863.0</td>\n",
       "      <td>205819.0</td>\n",
       "      <td>...</td>\n",
       "      <td>288845.0</td>\n",
       "      <td>256489.0</td>\n",
       "      <td>249879.0</td>\n",
       "      <td>276292.0</td>\n",
       "      <td>292926.0</td>\n",
       "      <td>221677.0</td>\n",
       "      <td>308573.0</td>\n",
       "      <td>289825.0</td>\n",
       "      <td>310192.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Est00385</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>...</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Est00386</td>\n",
       "      <td>19378.0</td>\n",
       "      <td>29735.0</td>\n",
       "      <td>23336.0</td>\n",
       "      <td>41908.0</td>\n",
       "      <td>41548.0</td>\n",
       "      <td>43017.0</td>\n",
       "      <td>40262.0</td>\n",
       "      <td>46648.0</td>\n",
       "      <td>33353.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68511.0</td>\n",
       "      <td>64390.0</td>\n",
       "      <td>58222.0</td>\n",
       "      <td>63731.0</td>\n",
       "      <td>71912.0</td>\n",
       "      <td>42255.0</td>\n",
       "      <td>69844.0</td>\n",
       "      <td>64880.0</td>\n",
       "      <td>70300.0</td>\n",
       "      <td>64261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Est00387</td>\n",
       "      <td>146778.0</td>\n",
       "      <td>368635.0</td>\n",
       "      <td>302365.0</td>\n",
       "      <td>411511.0</td>\n",
       "      <td>382508.0</td>\n",
       "      <td>313966.0</td>\n",
       "      <td>317081.0</td>\n",
       "      <td>410328.0</td>\n",
       "      <td>390995.0</td>\n",
       "      <td>...</td>\n",
       "      <td>269899.0</td>\n",
       "      <td>275897.0</td>\n",
       "      <td>272368.0</td>\n",
       "      <td>297006.0</td>\n",
       "      <td>336441.0</td>\n",
       "      <td>277761.0</td>\n",
       "      <td>295551.0</td>\n",
       "      <td>289471.0</td>\n",
       "      <td>300052.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Est00388</td>\n",
       "      <td>70477.0</td>\n",
       "      <td>119392.0</td>\n",
       "      <td>108627.0</td>\n",
       "      <td>162861.0</td>\n",
       "      <td>244248.0</td>\n",
       "      <td>177978.0</td>\n",
       "      <td>192803.0</td>\n",
       "      <td>219787.0</td>\n",
       "      <td>156910.0</td>\n",
       "      <td>...</td>\n",
       "      <td>280277.0</td>\n",
       "      <td>239542.0</td>\n",
       "      <td>229206.0</td>\n",
       "      <td>246336.0</td>\n",
       "      <td>211212.0</td>\n",
       "      <td>140453.0</td>\n",
       "      <td>267132.0</td>\n",
       "      <td>258828.0</td>\n",
       "      <td>275850.0</td>\n",
       "      <td>266479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Est00389</td>\n",
       "      <td>113877.0</td>\n",
       "      <td>85866.0</td>\n",
       "      <td>70837.0</td>\n",
       "      <td>201167.0</td>\n",
       "      <td>172279.0</td>\n",
       "      <td>157352.0</td>\n",
       "      <td>169090.0</td>\n",
       "      <td>158814.0</td>\n",
       "      <td>139005.0</td>\n",
       "      <td>...</td>\n",
       "      <td>274578.0</td>\n",
       "      <td>219889.0</td>\n",
       "      <td>207349.0</td>\n",
       "      <td>221419.0</td>\n",
       "      <td>202779.0</td>\n",
       "      <td>133830.0</td>\n",
       "      <td>273096.0</td>\n",
       "      <td>229219.0</td>\n",
       "      <td>237284.0</td>\n",
       "      <td>230593.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "t   id_estacion         1         2         3         4         5         6  \\\n",
       "0      Est00000   39059.0   74700.0   44356.0  237597.0  235918.0  181140.0   \n",
       "1      Est00001   48321.0  368193.0  293510.0  295068.0  200780.0  236938.0   \n",
       "2      Est00002   17515.0   49586.0   49395.0   42017.0   27076.0   38617.0   \n",
       "3      Est00003   40677.0  240827.0  223303.0  190028.0  148294.0  148437.0   \n",
       "4      Est00004   82758.0  163112.0  144023.0  240623.0  243391.0  205486.0   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "385    Est00385     405.0     405.0     405.0     405.0     405.0     405.0   \n",
       "386    Est00386   19378.0   29735.0   23336.0   41908.0   41548.0   43017.0   \n",
       "387    Est00387  146778.0  368635.0  302365.0  411511.0  382508.0  313966.0   \n",
       "388    Est00388   70477.0  119392.0  108627.0  162861.0  244248.0  177978.0   \n",
       "389    Est00389  113877.0   85866.0   70837.0  201167.0  172279.0  157352.0   \n",
       "\n",
       "t           7         8         9  ...       691       692       693  \\\n",
       "0    257563.0  257761.0  142208.0  ...  370097.0  305425.0  311695.0   \n",
       "1    152211.0  283677.0  114380.0  ...   97849.0   51293.0   93265.0   \n",
       "2     33000.0   43166.0   20616.0  ...   18127.0   12728.0   18583.0   \n",
       "3    220882.0  253680.0   76196.0  ...   68953.0   55081.0  102738.0   \n",
       "4    220086.0  255863.0  205819.0  ...  288845.0  256489.0  249879.0   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "385     405.0     405.0     405.0  ...     405.0     405.0     405.0   \n",
       "386   40262.0   46648.0   33353.0  ...   68511.0   64390.0   58222.0   \n",
       "387  317081.0  410328.0  390995.0  ...  269899.0  275897.0  272368.0   \n",
       "388  192803.0  219787.0  156910.0  ...  280277.0  239542.0  229206.0   \n",
       "389  169090.0  158814.0  139005.0  ...  274578.0  219889.0  207349.0   \n",
       "\n",
       "t         694       695       696       697       698       699       700  \n",
       "0    325139.0  240916.0  110586.0  394055.0  343256.0  374973.0  359923.0  \n",
       "1    116890.0  116176.0  109783.0  123092.0   79045.0   66206.0   94625.0  \n",
       "2     21357.0   21351.0   20371.0   22105.0   19344.0   12476.0   17916.0  \n",
       "3     92429.0  102303.0  101997.0   94795.0   90334.0   26519.0       NaN  \n",
       "4    276292.0  292926.0  221677.0  308573.0  289825.0  310192.0       NaN  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "385     405.0     405.0     405.0     405.0     405.0     405.0     405.0  \n",
       "386   63731.0   71912.0   42255.0   69844.0   64880.0   70300.0   64261.0  \n",
       "387  297006.0  336441.0  277761.0  295551.0  289471.0  300052.0       NaN  \n",
       "388  246336.0  211212.0  140453.0  267132.0  258828.0  275850.0  266479.0  \n",
       "389  221419.0  202779.0  133830.0  273096.0  229219.0  237284.0  230593.0  \n",
       "\n",
       "[390 rows x 701 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_piv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-moisture",
   "metadata": {},
   "source": [
    "# Funciones a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "structural-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas(model,Xv,yv):\n",
    "    print(\" Métricas para modelo de clasificación: \\n\")\n",
    "\n",
    "    print(\" Valor ROC : %.3f\"   %roc_auc_score( y_score=model.predict_proba(Xv)[:,1] , y_true=yv  )   )\n",
    "\n",
    "    print(\" Valor ACC : %.3f\\n\" %accuracy_score( y_pred=model.predict(Xv) , y_true=yv) )\n",
    "\n",
    "    print(\" Matriz de confusión: \", \"\\n\", confusion_matrix(y_pred=model.predict(Xv) , y_true=yv ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-algebra",
   "metadata": {},
   "source": [
    "# Funciones de agregación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "anonymous-stamp",
   "metadata": {
    "code_folding": [
     0,
     3,
     6,
     9,
     12,
     18,
     24,
     30,
     36,
     42,
     48,
     54,
     60,
     63,
     66,
     69
    ]
   },
   "outputs": [],
   "source": [
    "def sum_inc(l):\n",
    "    return sum( [int(y>x) for x,y in zip( l , l[1:] ) ] )\n",
    "\n",
    "def sum_dec(l):\n",
    "    return sum( [int(y<x) for x,y in zip( l , l[1:] ) ] )    \n",
    "\n",
    "def media_inc(l):\n",
    "    return np.mean( [int(y>x) for x,y in zip( l , l[1:] ) ] )\n",
    "\n",
    "def media_dec(l):\n",
    "    return np.mean( [int(y<x) for x,y in zip( l , l[1:] ) ] )  \n",
    "\n",
    "def delta_min(l):\n",
    "    try:\n",
    "        return min( [ float( y-x ) for x,y in zip( l , l[1:] ) ] )\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def delta_max(l):\n",
    "    try:\n",
    "        return max( [ float( y-x ) for x,y in zip( l , l[1:] ) ] )\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def delta_mean(l):\n",
    "    try:\n",
    "        return np.mean( [ float( y-x ) for x,y in zip( l , l[1:] ) ] )\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def delta_desv(l):  # revisar\n",
    "    try:\n",
    "        return np.std( [ float( y-x ) for x,y in zip( l , l[1:] ) ] )\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def pct_delta_min(l):\n",
    "    try:\n",
    "        return np.min( [ float( y-x )/x for x,y in zip( l , l[1:] ) ] )\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def pct_delta_max(l):\n",
    "    try:\n",
    "        return np.max( [ float( y-x )/x for x,y in zip( l , l[1:] ) ] )\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def pct_delta_mean(l):\n",
    "    try:\n",
    "        return np.mean( [ float( y-x )/x for x,y in zip( l , l[1:] ) ] )\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def pct_delta_desv(l): # revisar\n",
    "    try:\n",
    "        return np.std( [ float( y-x )/x for x,y in zip( l , l[1:] ) ] )\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def max_racha_inc(l):\n",
    "    return max( [ len(i) for i in \"\".join([ str( int(y>x)  ) for x,y in zip(l,l[1:])  ]).split('0')  ]   )\n",
    "\n",
    "def max_racha_dec(l):\n",
    "    return max( [ len(i) for i in \"\".join([ str( int(y<x)  ) for x,y in zip(l,l[1:])  ]).split('0')  ]   )\n",
    "\n",
    "def media_racha_inc(l):\n",
    "    return np.mean( [ len(i) for i in \"\".join([ str( int(y>x)  ) for x,y in zip(l,l[1:])  ]).split('0')  ]   )\n",
    "\n",
    "def media_racha_dec(l):\n",
    "    return np.mean( [ len(i) for i in \"\".join([ str( int(y<x)  ) for x,y in zip(l,l[1:])  ]).split('0')  ]   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-configuration",
   "metadata": {},
   "source": [
    "####### Ejemplo igual al excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "located-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [963,411,474,560,600,500,525,188,685]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "portuguese-junction",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21474808901015885"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_delta_mean(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "played-background",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.643617021276596"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_delta_max(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-kingdom",
   "metadata": {},
   "source": [
    "####### Termina ejemplo de excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "employed-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_func = ['sum','std','min','mean','max',sum_inc,sum_dec,\n",
    "media_inc, media_dec,\n",
    "delta_min, delta_max,\n",
    "delta_mean, delta_desv,\n",
    "pct_delta_min, pct_delta_max,\n",
    "pct_delta_mean, pct_delta_desv,\n",
    "max_racha_inc, max_racha_dec,\n",
    "media_racha_inc, media_racha_dec  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-twist",
   "metadata": {},
   "source": [
    "# Ventanas de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "suited-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdes = 1\n",
    "vobs = 10\n",
    "\n",
    "anclai = t_min + vobs -1\n",
    "anclaf = t_max - vdes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "white-standard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 10, 699)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdes , vobs , anclai , anclaf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-illinois",
   "metadata": {},
   "source": [
    "# Matriz de predictoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-present",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervalo:  0 10  Para pronosticar:  11\n",
      "intervalo:  1 11  Para pronosticar:  12\n",
      "intervalo:  2 12  Para pronosticar:  13\n",
      "intervalo:  3 13  Para pronosticar:  14\n",
      "intervalo:  4 14  Para pronosticar:  15\n",
      "intervalo:  5 15  Para pronosticar:  16\n",
      "intervalo:  6 16  Para pronosticar:  17\n",
      "intervalo:  7 17  Para pronosticar:  18\n",
      "intervalo:  8 18  Para pronosticar:  19\n",
      "intervalo:  9 19  Para pronosticar:  20\n",
      "intervalo:  10 20  Para pronosticar:  21\n",
      "intervalo:  11 21  Para pronosticar:  22\n",
      "intervalo:  12 22  Para pronosticar:  23\n",
      "intervalo:  13 23  Para pronosticar:  24\n",
      "intervalo:  14 24  Para pronosticar:  25\n",
      "intervalo:  15 25  Para pronosticar:  26\n",
      "intervalo:  16 26  Para pronosticar:  27\n",
      "intervalo:  17 27  Para pronosticar:  28\n",
      "intervalo:  18 28  Para pronosticar:  29\n",
      "intervalo:  19 29  Para pronosticar:  30\n",
      "intervalo:  20 30  Para pronosticar:  31\n",
      "intervalo:  21 31  Para pronosticar:  32\n",
      "intervalo:  22 32  Para pronosticar:  33\n",
      "intervalo:  23 33  Para pronosticar:  34\n",
      "intervalo:  24 34  Para pronosticar:  35\n",
      "intervalo:  25 35  Para pronosticar:  36\n",
      "intervalo:  26 36  Para pronosticar:  37\n",
      "intervalo:  27 37  Para pronosticar:  38\n",
      "intervalo:  28 38  Para pronosticar:  39\n",
      "intervalo:  29 39  Para pronosticar:  40\n",
      "intervalo:  30 40  Para pronosticar:  41\n",
      "intervalo:  31 41  Para pronosticar:  42\n",
      "intervalo:  32 42  Para pronosticar:  43\n",
      "intervalo:  33 43  Para pronosticar:  44\n",
      "intervalo:  34 44  Para pronosticar:  45\n",
      "intervalo:  35 45  Para pronosticar:  46\n",
      "intervalo:  36 46  Para pronosticar:  47\n",
      "intervalo:  37 47  Para pronosticar:  48\n",
      "intervalo:  38 48  Para pronosticar:  49\n",
      "intervalo:  39 49  Para pronosticar:  50\n",
      "intervalo:  40 50  Para pronosticar:  51\n",
      "intervalo:  41 51  Para pronosticar:  52\n",
      "intervalo:  42 52  Para pronosticar:  53\n",
      "intervalo:  43 53  Para pronosticar:  54\n",
      "intervalo:  44 54  Para pronosticar:  55\n",
      "intervalo:  45 55  Para pronosticar:  56\n",
      "intervalo:  46 56  Para pronosticar:  57\n",
      "intervalo:  47 57  Para pronosticar:  58\n",
      "intervalo:  48 58  Para pronosticar:  59\n",
      "intervalo:  49 59  Para pronosticar:  60\n",
      "intervalo:  50 60  Para pronosticar:  61\n",
      "intervalo:  51 61  Para pronosticar:  62\n",
      "intervalo:  52 62  Para pronosticar:  63\n",
      "intervalo:  53 63  Para pronosticar:  64\n",
      "intervalo:  54 64  Para pronosticar:  65\n",
      "intervalo:  55 65  Para pronosticar:  66\n",
      "intervalo:  56 66  Para pronosticar:  67\n",
      "intervalo:  57 67  Para pronosticar:  68\n",
      "intervalo:  58 68  Para pronosticar:  69\n",
      "intervalo:  59 69  Para pronosticar:  70\n",
      "intervalo:  60 70  Para pronosticar:  71\n",
      "intervalo:  61 71  Para pronosticar:  72\n",
      "intervalo:  62 72  Para pronosticar:  73\n",
      "intervalo:  63 73  Para pronosticar:  74\n",
      "intervalo:  64 74  Para pronosticar:  75\n",
      "intervalo:  65 75  Para pronosticar:  76\n",
      "intervalo:  66 76  Para pronosticar:  77\n",
      "intervalo:  67 77  Para pronosticar:  78\n",
      "intervalo:  68 78  Para pronosticar:  79\n",
      "intervalo:  69 79  Para pronosticar:  80\n",
      "intervalo:  70 80  Para pronosticar:  81\n",
      "intervalo:  71 81  Para pronosticar:  82\n",
      "intervalo:  72 82  Para pronosticar:  83\n",
      "intervalo:  73 83  Para pronosticar:  84\n",
      "intervalo:  74 84  Para pronosticar:  85\n",
      "intervalo:  75 85  Para pronosticar:  86\n",
      "intervalo:  76 86  Para pronosticar:  87\n",
      "intervalo:  77 87  Para pronosticar:  88\n",
      "intervalo:  78 88  Para pronosticar:  89\n",
      "intervalo:  79 89  Para pronosticar:  90\n",
      "intervalo:  80 90  Para pronosticar:  91\n",
      "intervalo:  81 91  Para pronosticar:  92\n",
      "intervalo:  82 92  Para pronosticar:  93\n",
      "intervalo:  83 93  Para pronosticar:  94\n",
      "intervalo:  84 94  Para pronosticar:  95\n",
      "intervalo:  85 95  Para pronosticar:  96\n",
      "intervalo:  86 96  Para pronosticar:  97\n",
      "intervalo:  87 97  Para pronosticar:  98\n",
      "intervalo:  88 98  Para pronosticar:  99\n",
      "intervalo:  89 99  Para pronosticar:  100\n",
      "intervalo:  90 100  Para pronosticar:  101\n",
      "intervalo:  91 101  Para pronosticar:  102\n",
      "intervalo:  92 102  Para pronosticar:  103\n",
      "intervalo:  93 103  Para pronosticar:  104\n",
      "intervalo:  94 104  Para pronosticar:  105\n",
      "intervalo:  95 105  Para pronosticar:  106\n",
      "intervalo:  96 106  Para pronosticar:  107\n",
      "intervalo:  97 107  Para pronosticar:  108\n",
      "intervalo:  98 108  Para pronosticar:  109\n",
      "intervalo:  99 109  Para pronosticar:  110\n",
      "intervalo:  100 110  Para pronosticar:  111\n",
      "intervalo:  101 111  Para pronosticar:  112\n",
      "intervalo:  102 112  Para pronosticar:  113\n",
      "intervalo:  103 113  Para pronosticar:  114\n",
      "intervalo:  104 114  Para pronosticar:  115\n",
      "intervalo:  105 115  Para pronosticar:  116\n",
      "intervalo:  106 116  Para pronosticar:  117\n",
      "intervalo:  107 117  Para pronosticar:  118\n",
      "intervalo:  108 118  Para pronosticar:  119\n",
      "intervalo:  109 119  Para pronosticar:  120\n",
      "intervalo:  110 120  Para pronosticar:  121\n",
      "intervalo:  111 121  Para pronosticar:  122\n",
      "intervalo:  112 122  Para pronosticar:  123\n",
      "intervalo:  113 123  Para pronosticar:  124\n",
      "intervalo:  114 124  Para pronosticar:  125\n",
      "intervalo:  115 125  Para pronosticar:  126\n",
      "intervalo:  116 126  Para pronosticar:  127\n",
      "intervalo:  117 127  Para pronosticar:  128\n",
      "intervalo:  118 128  Para pronosticar:  129\n",
      "intervalo:  119 129  Para pronosticar:  130\n",
      "intervalo:  120 130  Para pronosticar:  131\n",
      "intervalo:  121 131  Para pronosticar:  132\n",
      "intervalo:  122 132  Para pronosticar:  133\n",
      "intervalo:  123 133  Para pronosticar:  134\n",
      "intervalo:  124 134  Para pronosticar:  135\n",
      "intervalo:  125 135  Para pronosticar:  136\n",
      "intervalo:  126 136  Para pronosticar:  137\n",
      "intervalo:  127 137  Para pronosticar:  138\n",
      "intervalo:  128 138  Para pronosticar:  139\n",
      "intervalo:  129 139  Para pronosticar:  140\n",
      "intervalo:  130 140  Para pronosticar:  141\n",
      "intervalo:  131 141  Para pronosticar:  142\n",
      "intervalo:  132 142  Para pronosticar:  143\n",
      "intervalo:  133 143  Para pronosticar:  144\n",
      "intervalo:  134 144  Para pronosticar:  145\n",
      "intervalo:  135 145  Para pronosticar:  146\n",
      "intervalo:  136 146  Para pronosticar:  147\n",
      "intervalo:  137 147  Para pronosticar:  148\n",
      "intervalo:  138 148  Para pronosticar:  149\n",
      "intervalo:  139 149  Para pronosticar:  150\n",
      "intervalo:  140 150  Para pronosticar:  151\n",
      "intervalo:  141 151  Para pronosticar:  152\n",
      "intervalo:  142 152  Para pronosticar:  153\n",
      "intervalo:  143 153  Para pronosticar:  154\n",
      "intervalo:  144 154  Para pronosticar:  155\n",
      "intervalo:  145 155  Para pronosticar:  156\n",
      "intervalo:  146 156  Para pronosticar:  157\n",
      "intervalo:  147 157  Para pronosticar:  158\n",
      "intervalo:  148 158  Para pronosticar:  159\n",
      "intervalo:  149 159  Para pronosticar:  160\n",
      "intervalo:  150 160  Para pronosticar:  161\n",
      "intervalo:  151 161  Para pronosticar:  162\n",
      "intervalo:  152 162  Para pronosticar:  163\n",
      "intervalo:  153 163  Para pronosticar:  164\n",
      "intervalo:  154 164  Para pronosticar:  165\n",
      "intervalo:  155 165  Para pronosticar:  166\n",
      "intervalo:  156 166  Para pronosticar:  167\n",
      "intervalo:  157 167  Para pronosticar:  168\n",
      "intervalo:  158 168  Para pronosticar:  169\n",
      "intervalo:  159 169  Para pronosticar:  170\n",
      "intervalo:  160 170  Para pronosticar:  171\n",
      "intervalo:  161 171  Para pronosticar:  172\n",
      "intervalo:  162 172  Para pronosticar:  173\n",
      "intervalo:  163 173  Para pronosticar:  174\n",
      "intervalo:  164 174  Para pronosticar:  175\n",
      "intervalo:  165 175  Para pronosticar:  176\n",
      "intervalo:  166 176  Para pronosticar:  177\n",
      "intervalo:  167 177  Para pronosticar:  178\n",
      "intervalo:  168 178  Para pronosticar:  179\n",
      "intervalo:  169 179  Para pronosticar:  180\n",
      "intervalo:  170 180  Para pronosticar:  181\n",
      "intervalo:  171 181  Para pronosticar:  182\n",
      "intervalo:  172 182  Para pronosticar:  183\n",
      "intervalo:  173 183  Para pronosticar:  184\n",
      "intervalo:  174 184  Para pronosticar:  185\n",
      "intervalo:  175 185  Para pronosticar:  186\n",
      "intervalo:  176 186  Para pronosticar:  187\n",
      "intervalo:  177 187  Para pronosticar:  188\n",
      "intervalo:  178 188  Para pronosticar:  189\n",
      "intervalo:  179 189  Para pronosticar:  190\n",
      "intervalo:  180 190  Para pronosticar:  191\n",
      "intervalo:  181 191  Para pronosticar:  192\n",
      "intervalo:  182 192  Para pronosticar:  193\n",
      "intervalo:  183 193  Para pronosticar:  194\n",
      "intervalo:  184 194  Para pronosticar:  195\n",
      "intervalo:  185 195  Para pronosticar:  196\n",
      "intervalo:  186 196  Para pronosticar:  197\n",
      "intervalo:  187 197  Para pronosticar:  198\n",
      "intervalo:  188 198  Para pronosticar:  199\n",
      "intervalo:  189 199  Para pronosticar:  200\n",
      "intervalo:  190 200  Para pronosticar:  201\n",
      "intervalo:  191 201  Para pronosticar:  202\n",
      "intervalo:  192 202  Para pronosticar:  203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervalo:  193 203  Para pronosticar:  204\n",
      "intervalo:  194 204  Para pronosticar:  205\n",
      "intervalo:  195 205  Para pronosticar:  206\n",
      "intervalo:  196 206  Para pronosticar:  207\n",
      "intervalo:  197 207  Para pronosticar:  208\n",
      "intervalo:  198 208  Para pronosticar:  209\n",
      "intervalo:  199 209  Para pronosticar:  210\n",
      "intervalo:  200 210  Para pronosticar:  211\n",
      "intervalo:  201 211  Para pronosticar:  212\n",
      "intervalo:  202 212  Para pronosticar:  213\n",
      "intervalo:  203 213  Para pronosticar:  214\n",
      "intervalo:  204 214  Para pronosticar:  215\n",
      "intervalo:  205 215  Para pronosticar:  216\n",
      "intervalo:  206 216  Para pronosticar:  217\n",
      "intervalo:  207 217  Para pronosticar:  218\n",
      "intervalo:  208 218  Para pronosticar:  219\n",
      "intervalo:  209 219  Para pronosticar:  220\n",
      "intervalo:  210 220  Para pronosticar:  221\n",
      "intervalo:  211 221  Para pronosticar:  222\n",
      "intervalo:  212 222  Para pronosticar:  223\n",
      "intervalo:  213 223  Para pronosticar:  224\n",
      "intervalo:  214 224  Para pronosticar:  225\n",
      "intervalo:  215 225  Para pronosticar:  226\n",
      "intervalo:  216 226  Para pronosticar:  227\n",
      "intervalo:  217 227  Para pronosticar:  228\n",
      "intervalo:  218 228  Para pronosticar:  229\n",
      "intervalo:  219 229  Para pronosticar:  230\n",
      "intervalo:  220 230  Para pronosticar:  231\n",
      "intervalo:  221 231  Para pronosticar:  232\n",
      "intervalo:  222 232  Para pronosticar:  233\n",
      "intervalo:  223 233  Para pronosticar:  234\n",
      "intervalo:  224 234  Para pronosticar:  235\n",
      "intervalo:  225 235  Para pronosticar:  236\n",
      "intervalo:  226 236  Para pronosticar:  237\n",
      "intervalo:  227 237  Para pronosticar:  238\n",
      "intervalo:  228 238  Para pronosticar:  239\n",
      "intervalo:  229 239  Para pronosticar:  240\n",
      "intervalo:  230 240  Para pronosticar:  241\n",
      "intervalo:  231 241  Para pronosticar:  242\n",
      "intervalo:  232 242  Para pronosticar:  243\n",
      "intervalo:  233 243  Para pronosticar:  244\n",
      "intervalo:  234 244  Para pronosticar:  245\n",
      "intervalo:  235 245  Para pronosticar:  246\n",
      "intervalo:  236 246  Para pronosticar:  247\n",
      "intervalo:  237 247  Para pronosticar:  248\n",
      "intervalo:  238 248  Para pronosticar:  249\n",
      "intervalo:  239 249  Para pronosticar:  250\n",
      "intervalo:  240 250  Para pronosticar:  251\n",
      "intervalo:  241 251  Para pronosticar:  252\n",
      "intervalo:  242 252  Para pronosticar:  253\n",
      "intervalo:  243 253  Para pronosticar:  254\n",
      "intervalo:  244 254  Para pronosticar:  255\n",
      "intervalo:  245 255  Para pronosticar:  256\n",
      "intervalo:  246 256  Para pronosticar:  257\n",
      "intervalo:  247 257  Para pronosticar:  258\n",
      "intervalo:  248 258  Para pronosticar:  259\n",
      "intervalo:  249 259  Para pronosticar:  260\n",
      "intervalo:  250 260  Para pronosticar:  261\n",
      "intervalo:  251 261  Para pronosticar:  262\n",
      "intervalo:  252 262  Para pronosticar:  263\n",
      "intervalo:  253 263  Para pronosticar:  264\n",
      "intervalo:  254 264  Para pronosticar:  265\n",
      "intervalo:  255 265  Para pronosticar:  266\n",
      "intervalo:  256 266  Para pronosticar:  267\n",
      "intervalo:  257 267  Para pronosticar:  268\n",
      "intervalo:  258 268  Para pronosticar:  269\n",
      "intervalo:  259 269  Para pronosticar:  270\n",
      "intervalo:  260 270  Para pronosticar:  271\n",
      "intervalo:  261 271  Para pronosticar:  272\n",
      "intervalo:  262 272  Para pronosticar:  273\n",
      "intervalo:  263 273  Para pronosticar:  274\n",
      "intervalo:  264 274  Para pronosticar:  275\n",
      "intervalo:  265 275  Para pronosticar:  276\n",
      "intervalo:  266 276  Para pronosticar:  277\n",
      "intervalo:  267 277  Para pronosticar:  278\n",
      "intervalo:  268 278  Para pronosticar:  279\n",
      "intervalo:  269 279  Para pronosticar:  280\n",
      "intervalo:  270 280  Para pronosticar:  281\n",
      "intervalo:  271 281  Para pronosticar:  282\n",
      "intervalo:  272 282  Para pronosticar:  283\n",
      "intervalo:  273 283  Para pronosticar:  284\n",
      "intervalo:  274 284  Para pronosticar:  285\n",
      "intervalo:  275 285  Para pronosticar:  286\n",
      "intervalo:  276 286  Para pronosticar:  287\n",
      "intervalo:  277 287  Para pronosticar:  288\n",
      "intervalo:  278 288  Para pronosticar:  289\n",
      "intervalo:  279 289  Para pronosticar:  290\n",
      "intervalo:  280 290  Para pronosticar:  291\n",
      "intervalo:  281 291  Para pronosticar:  292\n",
      "intervalo:  282 292  Para pronosticar:  293\n",
      "intervalo:  283 293  Para pronosticar:  294\n",
      "intervalo:  284 294  Para pronosticar:  295\n",
      "intervalo:  285 295  Para pronosticar:  296\n",
      "intervalo:  286 296  Para pronosticar:  297\n",
      "intervalo:  287 297  Para pronosticar:  298\n",
      "intervalo:  288 298  Para pronosticar:  299\n",
      "intervalo:  289 299  Para pronosticar:  300\n",
      "intervalo:  290 300  Para pronosticar:  301\n",
      "intervalo:  291 301  Para pronosticar:  302\n",
      "intervalo:  292 302  Para pronosticar:  303\n",
      "intervalo:  293 303  Para pronosticar:  304\n",
      "intervalo:  294 304  Para pronosticar:  305\n",
      "intervalo:  295 305  Para pronosticar:  306\n",
      "intervalo:  296 306  Para pronosticar:  307\n",
      "intervalo:  297 307  Para pronosticar:  308\n",
      "intervalo:  298 308  Para pronosticar:  309\n",
      "intervalo:  299 309  Para pronosticar:  310\n",
      "intervalo:  300 310  Para pronosticar:  311\n",
      "intervalo:  301 311  Para pronosticar:  312\n",
      "intervalo:  302 312  Para pronosticar:  313\n",
      "intervalo:  303 313  Para pronosticar:  314\n",
      "intervalo:  304 314  Para pronosticar:  315\n",
      "intervalo:  305 315  Para pronosticar:  316\n",
      "intervalo:  306 316  Para pronosticar:  317\n",
      "intervalo:  307 317  Para pronosticar:  318\n",
      "intervalo:  308 318  Para pronosticar:  319\n",
      "intervalo:  309 319  Para pronosticar:  320\n",
      "intervalo:  310 320  Para pronosticar:  321\n",
      "intervalo:  311 321  Para pronosticar:  322\n",
      "intervalo:  312 322  Para pronosticar:  323\n",
      "intervalo:  313 323  Para pronosticar:  324\n",
      "intervalo:  314 324  Para pronosticar:  325\n",
      "intervalo:  315 325  Para pronosticar:  326\n",
      "intervalo:  316 326  Para pronosticar:  327\n",
      "intervalo:  317 327  Para pronosticar:  328\n",
      "intervalo:  318 328  Para pronosticar:  329\n",
      "intervalo:  319 329  Para pronosticar:  330\n",
      "intervalo:  320 330  Para pronosticar:  331\n",
      "intervalo:  321 331  Para pronosticar:  332\n",
      "intervalo:  322 332  Para pronosticar:  333\n",
      "intervalo:  323 333  Para pronosticar:  334\n",
      "intervalo:  324 334  Para pronosticar:  335\n",
      "intervalo:  325 335  Para pronosticar:  336\n",
      "intervalo:  326 336  Para pronosticar:  337\n",
      "intervalo:  327 337  Para pronosticar:  338\n",
      "intervalo:  328 338  Para pronosticar:  339\n",
      "intervalo:  329 339  Para pronosticar:  340\n",
      "intervalo:  330 340  Para pronosticar:  341\n",
      "intervalo:  331 341  Para pronosticar:  342\n",
      "intervalo:  332 342  Para pronosticar:  343\n",
      "intervalo:  333 343  Para pronosticar:  344\n",
      "intervalo:  334 344  Para pronosticar:  345\n",
      "intervalo:  335 345  Para pronosticar:  346\n",
      "intervalo:  336 346  Para pronosticar:  347\n",
      "intervalo:  337 347  Para pronosticar:  348\n",
      "intervalo:  338 348  Para pronosticar:  349\n",
      "intervalo:  339 349  Para pronosticar:  350\n",
      "intervalo:  340 350  Para pronosticar:  351\n",
      "intervalo:  341 351  Para pronosticar:  352\n",
      "intervalo:  342 352  Para pronosticar:  353\n",
      "intervalo:  343 353  Para pronosticar:  354\n",
      "intervalo:  344 354  Para pronosticar:  355\n",
      "intervalo:  345 355  Para pronosticar:  356\n",
      "intervalo:  346 356  Para pronosticar:  357\n",
      "intervalo:  347 357  Para pronosticar:  358\n",
      "intervalo:  348 358  Para pronosticar:  359\n",
      "intervalo:  349 359  Para pronosticar:  360\n",
      "intervalo:  350 360  Para pronosticar:  361\n",
      "intervalo:  351 361  Para pronosticar:  362\n",
      "intervalo:  352 362  Para pronosticar:  363\n",
      "intervalo:  353 363  Para pronosticar:  364\n",
      "intervalo:  354 364  Para pronosticar:  365\n",
      "intervalo:  355 365  Para pronosticar:  366\n",
      "intervalo:  356 366  Para pronosticar:  367\n",
      "intervalo:  357 367  Para pronosticar:  368\n",
      "intervalo:  358 368  Para pronosticar:  369\n",
      "intervalo:  359 369  Para pronosticar:  370\n",
      "intervalo:  360 370  Para pronosticar:  371\n",
      "intervalo:  361 371  Para pronosticar:  372\n",
      "intervalo:  362 372  Para pronosticar:  373\n",
      "intervalo:  363 373  Para pronosticar:  374\n",
      "intervalo:  364 374  Para pronosticar:  375\n",
      "intervalo:  365 375  Para pronosticar:  376\n",
      "intervalo:  366 376  Para pronosticar:  377\n",
      "intervalo:  367 377  Para pronosticar:  378\n",
      "intervalo:  368 378  Para pronosticar:  379\n",
      "intervalo:  369 379  Para pronosticar:  380\n",
      "intervalo:  370 380  Para pronosticar:  381\n",
      "intervalo:  371 381  Para pronosticar:  382\n",
      "intervalo:  372 382  Para pronosticar:  383\n",
      "intervalo:  373 383  Para pronosticar:  384\n",
      "intervalo:  374 384  Para pronosticar:  385\n",
      "intervalo:  375 385  Para pronosticar:  386\n",
      "intervalo:  376 386  Para pronosticar:  387\n",
      "intervalo:  377 387  Para pronosticar:  388\n",
      "intervalo:  378 388  Para pronosticar:  389\n",
      "intervalo:  379 389  Para pronosticar:  390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervalo:  380 390  Para pronosticar:  391\n",
      "intervalo:  381 391  Para pronosticar:  392\n",
      "intervalo:  382 392  Para pronosticar:  393\n",
      "intervalo:  383 393  Para pronosticar:  394\n",
      "intervalo:  384 394  Para pronosticar:  395\n",
      "intervalo:  385 395  Para pronosticar:  396\n",
      "intervalo:  386 396  Para pronosticar:  397\n",
      "intervalo:  387 397  Para pronosticar:  398\n",
      "intervalo:  388 398  Para pronosticar:  399\n",
      "intervalo:  389 399  Para pronosticar:  400\n",
      "intervalo:  390 400  Para pronosticar:  401\n",
      "intervalo:  391 401  Para pronosticar:  402\n",
      "intervalo:  392 402  Para pronosticar:  403\n",
      "intervalo:  393 403  Para pronosticar:  404\n",
      "intervalo:  394 404  Para pronosticar:  405\n",
      "intervalo:  395 405  Para pronosticar:  406\n",
      "intervalo:  396 406  Para pronosticar:  407\n",
      "intervalo:  397 407  Para pronosticar:  408\n",
      "intervalo:  398 408  Para pronosticar:  409\n",
      "intervalo:  399 409  Para pronosticar:  410\n",
      "intervalo:  400 410  Para pronosticar:  411\n",
      "intervalo:  401 411  Para pronosticar:  412\n",
      "intervalo:  402 412  Para pronosticar:  413\n",
      "intervalo:  403 413  Para pronosticar:  414\n",
      "intervalo:  404 414  Para pronosticar:  415\n",
      "intervalo:  405 415  Para pronosticar:  416\n",
      "intervalo:  406 416  Para pronosticar:  417\n",
      "intervalo:  407 417  Para pronosticar:  418\n",
      "intervalo:  408 418  Para pronosticar:  419\n",
      "intervalo:  409 419  Para pronosticar:  420\n",
      "intervalo:  410 420  Para pronosticar:  421\n",
      "intervalo:  411 421  Para pronosticar:  422\n",
      "intervalo:  412 422  Para pronosticar:  423\n",
      "intervalo:  413 423  Para pronosticar:  424\n",
      "intervalo:  414 424  Para pronosticar:  425\n",
      "intervalo:  415 425  Para pronosticar:  426\n",
      "intervalo:  416 426  Para pronosticar:  427\n",
      "intervalo:  417 427  Para pronosticar:  428\n",
      "intervalo:  418 428  Para pronosticar:  429\n",
      "intervalo:  419 429  Para pronosticar:  430\n",
      "intervalo:  420 430  Para pronosticar:  431\n",
      "intervalo:  421 431  Para pronosticar:  432\n",
      "intervalo:  422 432  Para pronosticar:  433\n",
      "intervalo:  423 433  Para pronosticar:  434\n",
      "intervalo:  424 434  Para pronosticar:  435\n",
      "intervalo:  425 435  Para pronosticar:  436\n",
      "intervalo:  426 436  Para pronosticar:  437\n",
      "intervalo:  427 437  Para pronosticar:  438\n",
      "intervalo:  428 438  Para pronosticar:  439\n",
      "intervalo:  429 439  Para pronosticar:  440\n",
      "intervalo:  430 440  Para pronosticar:  441\n",
      "intervalo:  431 441  Para pronosticar:  442\n",
      "intervalo:  432 442  Para pronosticar:  443\n",
      "intervalo:  433 443  Para pronosticar:  444\n",
      "intervalo:  434 444  Para pronosticar:  445\n",
      "intervalo:  435 445  Para pronosticar:  446\n",
      "intervalo:  436 446  Para pronosticar:  447\n",
      "intervalo:  437 447  Para pronosticar:  448\n",
      "intervalo:  438 448  Para pronosticar:  449\n",
      "intervalo:  439 449  Para pronosticar:  450\n",
      "intervalo:  440 450  Para pronosticar:  451\n",
      "intervalo:  441 451  Para pronosticar:  452\n",
      "intervalo:  442 452  Para pronosticar:  453\n",
      "intervalo:  443 453  Para pronosticar:  454\n",
      "intervalo:  444 454  Para pronosticar:  455\n",
      "intervalo:  445 455  Para pronosticar:  456\n",
      "intervalo:  446 456  Para pronosticar:  457\n",
      "intervalo:  447 457  Para pronosticar:  458\n",
      "intervalo:  448 458  Para pronosticar:  459\n",
      "intervalo:  449 459  Para pronosticar:  460\n",
      "intervalo:  450 460  Para pronosticar:  461\n",
      "intervalo:  451 461  Para pronosticar:  462\n",
      "intervalo:  452 462  Para pronosticar:  463\n",
      "intervalo:  453 463  Para pronosticar:  464\n",
      "intervalo:  454 464  Para pronosticar:  465\n",
      "intervalo:  455 465  Para pronosticar:  466\n",
      "intervalo:  456 466  Para pronosticar:  467\n",
      "intervalo:  457 467  Para pronosticar:  468\n",
      "intervalo:  458 468  Para pronosticar:  469\n",
      "intervalo:  459 469  Para pronosticar:  470\n"
     ]
    }
   ],
   "source": [
    "lst_aux = []\n",
    "\n",
    "ancla = anclai + vobs\n",
    "\n",
    "for ancla in range( anclai , anclaf + 1 ):\n",
    "    \n",
    "    print('intervalo: ', ancla - anclai , ancla , \" Para pronosticar: \", ancla+vdes)\n",
    "    \n",
    "    aux = df[ ( df['t'] > ancla-anclai ) & \n",
    "               (df['t'] <= ancla)  ].reset_index(drop=True).copy()\n",
    "    \n",
    "    aux = aux.pivot_table( index = um,\n",
    "                           values = 'afluencia',\n",
    "                           aggfunc = lst_func )\n",
    "     \n",
    "    aux.columns = [f'v_{i}_{j}' for i,j in aux.columns]\n",
    "    \n",
    "    aux.insert(0,'ancla',ancla)\n",
    "    \n",
    "    aux.reset_index(inplace=True)\n",
    "    \n",
    "    lst_aux.append(aux)\n",
    "    \n",
    "X = pd.concat( lst_aux , ignore_index=True ).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_pickle(\"datosEstaciones/X_aux.pkl\",protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-bobby",
   "metadata": {},
   "source": [
    "# Vector solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-guard",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst_aux = []\n",
    "\n",
    "for ancla in range( anclai , anclaf + 1 ):\n",
    "    \n",
    "    print('intervalo: ', ancla - anclai , ancla , \" Para pronosticar: \", ancla+vdes)\n",
    "    \n",
    "    aux = df[ ( df['t'] > ancla-anclai ) & (df['t'] <= ancla + vdes)  ].reset_index(drop=True).copy()\n",
    "    \n",
    "    aux = aux.pivot_table( index = um,\n",
    "                           columns = 't',\n",
    "                           values = 'afluencia')\n",
    "    \n",
    "    aux['y'] = aux[ ancla + vdes ]\n",
    "    \n",
    "    aux = aux[['y']]\n",
    "    \n",
    "    aux.insert(0,'ancla',ancla)\n",
    "    \n",
    "    aux.reset_index(inplace=True)\n",
    "    \n",
    "    lst_aux.append(aux)\n",
    "    \n",
    "y = pd.concat( lst_aux , ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-ancient",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-diesel",
   "metadata": {},
   "source": [
    "# TAD preliminar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-madison",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tad = X.merge( y , on = ['id_estacion','ancla'] , how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-sellers",
   "metadata": {},
   "source": [
    "# Target 2  - Para el álta demanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-construction",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "tad['v_max_racha_inc_afluencia' ].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-danish",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "tad['v_max_racha_inc_afluencia' ].value_counts(True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad.apply( lambda x: (x['v_max_racha_inc_afluencia'] >= 3) , axis=True ).astype(int).value_counts(True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad['y2'] = tad.apply( lambda x: (x['v_max_racha_inc_afluencia'] >= 3) , axis=True ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-buffalo",
   "metadata": {},
   "source": [
    "# Persistir TAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad.to_pickle( 'datosEstaciones/tad_preliminar.pkl',protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-sector",
   "metadata": {},
   "source": [
    "# Análisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-exhibition",
   "metadata": {},
   "source": [
    "## Variables Continuas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "varc = tad.filter(like='v_').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(varc), varc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tad[varc].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[varc].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-fountain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X[varc[:9]].hist(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-sperm",
   "metadata": {},
   "source": [
    "### Valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = 1 - X[varc].describe().T[['count']] / len(tad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-things",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape , X.dropna().shape , X.dropna().shape[0] / X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-diesel",
   "metadata": {},
   "source": [
    "### Impuntación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto puede ser tan complejo o sofisticado como negocio o la variable lo requiera\n",
    "im = SimpleImputer(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[varc] = im.transform(X[varc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-pontiac",
   "metadata": {},
   "source": [
    "### Distribución alterada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = pd.DataFrame( map( lambda v:  ( v , ks_2samp( tad[v].dropna()  , X[v] ).statistic  ), varc ) , columns=['var','ks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Valores mayores a .1 son dist. alteradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-tomorrow",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-pattern",
   "metadata": {},
   "source": [
    "### Varianza "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt = VarianceThreshold(threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-exclusive",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vt.fit( X[varc] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_varianza = [ v for v,u in zip(varc , vt.get_support() ) if not(u) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-dealing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X[sin_varianza].hist(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop( sin_varianza , axis = 1  , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "varc = [v for v in varc if v not in sin_varianza]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(varc), varc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-nothing",
   "metadata": {},
   "source": [
    "### Extremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = X[varc].describe(percentiles=[0.01,0.99]).T[['1%','99%']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v, li, ls in ext.values:\n",
    "    X[f'ol_{v}'] = ( ( X[v] < li ) | (X[v] > ls) ).astype(int)\n",
    "    \n",
    "X['ext'] = X.filter(like='ol_').max(axis=1)\n",
    "X.drop(X.filter(like='ol_').columns , axis=1 , inplace=True)\n",
    "X['ext'].value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape , tad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[ um + ['ancla'] ] = tad[ um + ['ancla']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[ X['ext'] == 0 ].reset_index(drop=True).drop(['ext'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape , tad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-wales",
   "metadata": {},
   "source": [
    "### Multivariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-thanks",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X[varc].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-swiss",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(X[varc].sample(500) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-madrid",
   "metadata": {},
   "source": [
    "## Multicolinealidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = VarClusHi( df = X[varc] , feat_list=varc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc.varclus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = vc.rsquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = rs.sort_values(by=['Cluster','RS_Ratio'],ascending=[1,1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs['id'] = rs.groupby('Cluster').cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-browser",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "varc = rs.loc[ rs.id == 1 ]['Variable'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "varc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[varc].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-token",
   "metadata": {},
   "source": [
    "# TAD Final - Modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-details",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "X[ um +['ancla'] + varc ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-emphasis",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_1 = X[ um + ['ancla'] + varc ].merge( y , on=[ 'id_estacion', 'ancla'] , how='inner').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-paradise",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tad_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_2 = X[ um + ['ancla'] + varc ].merge( tad[um+['ancla','y2']] , \n",
    "                                          on=[ 'id_estacion', 'ancla'] , \n",
    "                                          how='inner').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-latvia",
   "metadata": {},
   "source": [
    "# Modelo (1) : Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_1.shape , tad_1.loc[ ~tad_1['y'].isna() ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_1 = tad_1.loc[ ~tad_1['y'].isna() ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_1['y'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_1.loc[ tad_1['y'] < 600000 ]['y'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tad_1.loc[ tad_1['y'] < 600000 ].shape[0] / tad_1.shape[0] ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_1 = tad_1.loc[ tad_1['y'] < 600000 ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-degree",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tad_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-charleston",
   "metadata": {},
   "source": [
    "## Partición de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt , Xv , yt , yv = train_test_split( tad_1[varc] , tad_1['y'] , train_size=0.7 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt.shape, yt.shape[0] , Xv.shape, yv.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-sport",
   "metadata": {},
   "source": [
    "## Modelo / Entrenamiento - Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_1 = LinearRegression(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_1.fit( Xt , yt )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-warehouse",
   "metadata": {},
   "source": [
    "## Parámetros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_1.intercept_ , modelo_1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-belgium",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error( y_pred = modelo_1.predict(Xt) , y_true = yt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error( y_pred = modelo_1.predict(Xv) , y_true = yv )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-organ",
   "metadata": {},
   "source": [
    "## Visualización de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-punishment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yv.hist()\n",
    "plt.hist( modelo_1.predict(Xv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xv['y'] = yv\n",
    "Xv['y^'] = modelo_1.predict(Xv[varc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-decline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-south",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.displot( yv ,  kde_kws = {'cumulative':True} )\n",
    "sns.displot( Xv['y^'] ,  kde_kws = {'cumulative':True} ) # error en hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xv['error'] = Xv['y^'] - Xv['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xv['error'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-prison",
   "metadata": {},
   "source": [
    "# Modelo (2) : Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-paste",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "tad_2.y2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-duplicate",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "tad_2.y2.value_counts(True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tad_2[varc]\n",
    "y = tad_2['y2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-story",
   "metadata": {},
   "source": [
    "## Partición de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt , Xv , yt , yv = train_test_split( tad_2[varc] , tad_2['y2'] , train_size=0.7 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt.shape, yt.shape[0] , Xv.shape, yv.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-billion",
   "metadata": {},
   "source": [
    "## Modelo / Entrenamiento - Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_2.fit( Xt , yt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_2.coef_ , modelo_2.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-genesis",
   "metadata": {},
   "source": [
    "## Evaluación de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-width",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(modelo_2.predict_proba( Xv ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(modelo_2.predict( Xv )).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-proposal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_roc_curve( y_true=yt , y_probas= modelo_2.predict_proba(Xt) , curves='macro' )\n",
    "plot_roc_curve( y_true=yv , y_probas= modelo_2.predict_proba(Xv) , curves='macro' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas( modelo_2 , Xv, yv )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "236.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
